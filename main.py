import requests
import re
import dns.resolver
from dns.resolver import NoNameservers, NXDOMAIN, Timeout
from dns.exception import DNSException
from collections import defaultdict
from datetime import datetime
from config import UPSTREAM_RULES, OUTPUT_FILE, SUPPORTED_RULE_TYPES, EXCLUDED_PREFIXES

def download_rule(url: str) -> list[str]:
    """ä¸‹è½½å•ä¸ªä¸Šæ¸¸è§„åˆ™ï¼Œè¿”å›æœ‰æ•ˆè§„åˆ™åˆ—è¡¨ï¼ˆè¿‡æ»¤æ³¨é‡Š/ç©ºè¡Œï¼‰"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=60)
        response.raise_for_status()
        response.encoding = response.apparent_encoding or "utf-8"
        rules = response.text.split("\n")
        comment_prefixes = EXCLUDED_PREFIXES[:3]  # æå–æ³¨é‡Šå‰ç¼€ï¼ˆ!, #, //ï¼‰
        valid_rules = [
            rule.strip() for rule in rules
            if rule.strip() and not rule.strip().startswith(comment_prefixes)
        ]
        print(f"âœ… æˆåŠŸä¸‹è½½ {url} | æœ‰æ•ˆè§„åˆ™æ•°ï¼š{len(valid_rules)}")
        return valid_rules
    except requests.exceptions.ConnectionError:
        print(f"âŒ ä¸‹è½½å¤±è´¥ {url} | é”™è¯¯ï¼šç½‘ç»œè¿æ¥è¶…æ—¶/æ— æ³•è®¿é—®")
        return []
    except requests.exceptions.HTTPError as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ {url} | é”™è¯¯ï¼šHTTP çŠ¶æ€ç  {e.response.status_code}")
        return []
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥ {url} | é”™è¯¯ï¼š{str(e)}")
        return []

def convert_hosts_to_adguard(rule: str) -> str | None:
    """å°† Hosts è§„åˆ™è½¬æ¢ä¸º AdGuard è§„åˆ™ ||åŸŸå^"""
    hosts_pattern = r"^(0\.0\.0\.0|127\.0\.0\.1|::1)\s+([a-zA-Z0-9.-]+\.[a-zA-Z]+)"
    match = re.match(hosts_pattern, rule)
    if match:
        domain = match.group(2)
        return f"||{domain}^"
    return None

def check_domain_resolvable(domain: str) -> bool:
    """æ£€æŸ¥åŸŸåæ˜¯å¦å¯è§£æï¼ˆå¤„ç†å¼‚å¸¸å¹¶ä½¿ç”¨æ–°æ–¹æ³•ï¼‰"""
    resolver = dns.resolver.Resolver()
    # æŒ‡å®šå¯é çš„DNSæœåŠ¡å™¨ï¼Œé¿å…é»˜è®¤æœåŠ¡å™¨è§£æå¤±è´¥
    resolver.nameservers = ['8.8.8.8', '8.8.4.4', '1.1.1.1', '223.5.5.5']
    
    try:
        # ä½¿ç”¨æ–°æ–¹æ³• resolve() æ›¿ä»£ deprecated çš„ query()
        resolver.resolve(domain, 'A')
        return True  # è§£ææˆåŠŸ
    except (NoNameservers, NXDOMAIN, Timeout, DNSException):
        # æ•è·æ‰€æœ‰å¯èƒ½çš„DNSå¼‚å¸¸ï¼Œé¿å…å•ä¸ªåŸŸåè§£æå¤±è´¥å¯¼è‡´è„šæœ¬å´©æºƒ
        return False  # è§£æå¤±è´¥

def extract_rule_parts(rule: str) -> tuple[str, str, bool, bool, str]:
    """è§£æè§„åˆ™ï¼šè¿”å›ï¼ˆåŸºç¡€åŸŸå/æ³›åŒ–åŸŸå, å®Œæ•´è§„åˆ™, æ˜¯å¦ç™½åå•, æ˜¯å¦å¸¦important, åŸå§‹åŸŸåï¼‰"""
    # åŒ¹é…ç™½åå•è§„åˆ™ @@||åŸŸå^$å‚æ•° æˆ– @@||åŸŸå^
    whitelist_pattern = r"^@@\|\|([a-zA-Z0-9.-]+\.[a-zA-Z]+)(\^.*)?$"
    # åŒ¹é…é»‘åå•è§„åˆ™ ||åŸŸå^$å‚æ•° æˆ– ||åŸŸå^
    blacklist_pattern = r"^\|\|([a-zA-Z0-9.-]+\.[a-zA-Z]+)(\^.*)?$"
    
    is_whitelist = False
    has_important = False
    base_domain = ""
    generalized_domain = ""
    original_domain = ""
    
    # å¤„ç†ç™½åå•
    whitelist_match = re.match(whitelist_pattern, rule)
    if whitelist_match:
        is_whitelist = True
        original_domain = whitelist_match.group(1)
        base_domain = original_domain
        params = whitelist_match.group(2) or ""
        if "$important" in params:
            has_important = True
    else:
        # å¤„ç†é»‘åå•
        blacklist_match = re.match(blacklist_pattern, rule)
        if blacklist_match:
            original_domain = blacklist_match.group(1)
            base_domain = original_domain
            params = blacklist_match.group(2) or ""
            if "$important" in params:
                has_important = True
    
    if base_domain:
        # ç”Ÿæˆæ³›åŒ–åŸŸåï¼ˆå¦‚ a36243.actonservice.com â†’ a*.actonservice.comï¼‰
        num_pattern = r"^([a-zA-Z]+)\d+\.(.*)$"
        num_match = re.match(num_pattern, base_domain)
        if num_match:
            generalized_domain = f"{num_match.group(1)}*.{num_match.group(2)}"
        else:
            generalized_domain = base_domain
    
    return (generalized_domain, rule, is_whitelist, has_important, original_domain)

def merge_rules(all_rules: list[str]) -> list[str]:
    """æ•´åˆè§„åˆ™ï¼šæ³›åŒ–åˆå¹¶ã€é»‘ç™½åå•å†²çªå¤„ç†ã€ä¼˜å…ˆçº§ä¿ç•™ã€DNSéªŒè¯"""
    rule_groups = defaultdict(dict)  # key: æ³›åŒ–åŸŸå, value: {is_whitelist: {has_important: rule}}
    
    for rule in all_rules:
        # è½¬æ¢ Hosts è§„åˆ™ä¸º AdGuard æ ¼å¼
        converted_rule = convert_hosts_to_adguard(rule)
        final_rule = converted_rule if converted_rule else rule
        
        # è¿‡æ»¤ä¸æ”¯æŒçš„è§„åˆ™ç±»å‹
        if not any(final_rule.startswith(prefix) for prefix in ["||", "@@||"]):
            continue
        
        # è§£æè§„åˆ™ç»„æˆéƒ¨åˆ†
        generalized_domain, full_rule, is_whitelist, has_important, original_domain = extract_rule_parts(final_rule)
        if not generalized_domain:
            continue
        
        # DNSéªŒè¯ï¼šä»…ä¿ç•™å¯è§£æçš„åŸŸåï¼ˆå¯é€‰é€»è¾‘ï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
        # æ³¨æ„ï¼šç™½åå•é€šå¸¸éœ€è¦ä¿ç•™ï¼Œå³ä½¿åŸŸåä¸å¯è§£æ
        if not is_whitelist and not check_domain_resolvable(original_domain):
            continue  # è·³è¿‡ä¸å¯è§£æçš„é»‘åå•åŸŸå
        
        # æŒ‰æ³›åŒ–åŸŸååˆ†ç»„å¤„ç†è§„åˆ™ä¼˜å…ˆçº§
        domain_group = rule_groups[generalized_domain]
        
        # ç™½åå•ä¼˜å…ˆçº§ > é»‘åå•
        if is_whitelist:
            if is_whitelist not in domain_group:
                domain_group[is_whitelist] = {}
            # ä¿ç•™å¸¦importantçš„è§„åˆ™ï¼Œæˆ–æ›´æ–°ä¸ºæ›´é«˜ä¼˜å…ˆçº§è§„åˆ™
            if has_important or not domain_group[is_whitelist]:
                domain_group[is_whitelist][has_important] = full_rule
        else:
            # é»‘åå•ï¼šä»…å½“æ²¡æœ‰ç™½åå•æ—¶æ‰å¤„ç†
            if True not in domain_group:  # æ— ç™½åå•è§„åˆ™
                if is_whitelist not in domain_group:
                    domain_group[is_whitelist] = {}
                # ä¿ç•™å¸¦importantçš„è§„åˆ™ï¼Œæˆ–æ›´æ–°ä¸ºæ›´é«˜ä¼˜å…ˆçº§è§„åˆ™
                if has_important or not domain_group[is_whitelist]:
                    domain_group[is_whitelist][has_important] = full_rule
    
    # ç”Ÿæˆæœ€ç»ˆè§„åˆ™åˆ—è¡¨
    final_rules = []
    for domain, groups in rule_groups.items():
        if True in groups:  # ä¼˜å…ˆé€‰æ‹©ç™½åå•
            whitelist_group = groups[True]
            if True in whitelist_group:
                final_rules.append(whitelist_group[True])
            else:
                final_rules.append(next(iter(whitelist_group.values())))
        else:  # ä»…ä¿ç•™é»‘åå•
            blacklist_group = groups[False]
            if True in blacklist_group:
                final_rules.append(blacklist_group[True])
            else:
                final_rules.append(next(iter(blacklist_group.values())))
    
    # æŒ‰åŸŸåæ’åºï¼Œä¿è¯è§„åˆ™æœ‰åºæ€§
    final_rules.sort()
    return final_rules

def generate_final_file(rules: list[str]):
    """ç”Ÿæˆæœ€ç»ˆçš„åˆå¹¶è§„åˆ™æ–‡ä»¶ï¼ŒåŒ…å«å…ƒä¿¡æ¯"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")  # ç²¾ç¡®åˆ°ç§’
    
    header = f"""# AdGuard Home åˆå¹¶è§„åˆ™æ–‡ä»¶
# è‡ªåŠ¨ç”Ÿæˆæµç¨‹ï¼šä¸‹è½½ä¸Šæ¸¸è§„åˆ™ â†’ æ ¼å¼è½¬æ¢ â†’ æ³›åŒ–åˆå¹¶ â†’ å†²çªå¤„ç† â†’ DNSéªŒè¯
# ä¸Šæ¸¸è§„åˆ™æ¥æºï¼š
{chr(10).join([f"- {url}" for url in UPSTREAM_RULES])}
# è§„åˆ™æ•°é‡ï¼š{len(rules)}  # ç”¨äºREADMEè‡ªåŠ¨æå–
# æœ€åæ›´æ–°æ—¶é—´ï¼š{current_time}  # ç”¨äºREADMEè‡ªåŠ¨æå–
# ç»´æŠ¤è€…ï¼šguandashengï¼ˆGitHub ç”¨æˆ·åï¼‰
# å®šæ—¶æ›´æ–°ï¼šæ¯ 8 å°æ—¶è‡ªåŠ¨åŒæ­¥ä¸Šæ¸¸è§„åˆ™
# ä¼˜åŒ–è¯´æ˜ï¼š
# 1. Hosts è§„åˆ™å·²è½¬æ¢ä¸º AdGuard æ ¼å¼ï¼ˆ||åŸŸå^ï¼‰
# 2. æ•°å­—åç¼€å­åŸŸåè‡ªåŠ¨æ³›åŒ–ï¼ˆå¦‚ a36243.actonservice.com â†’ a*.actonservice.comï¼‰
# 3. é»‘ç™½åå•å†²çªæ—¶ï¼Œä¼˜å…ˆä¿ç•™ç™½åå•è§„åˆ™
# 4. ç›¸åŒåŸŸåä¿ç•™å¸¦ $important ä¼˜å…ˆçº§çš„è§„åˆ™
# 5. é»‘åå•è§„åˆ™è‡ªåŠ¨è¿‡æ»¤ä¸å¯è§£æçš„æ— æ•ˆåŸŸå
# 6. æ‰€æœ‰è§„åˆ™å·²å»é‡å¹¶æŒ‰åŸŸåæ’åº

"""
    
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(header)
        f.write("\n".join(rules))
    
    print(f"\nğŸ‰ åˆå¹¶å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{OUTPUT_FILE}")
    print(f"ğŸ“Š æœ€ç»ˆè§„åˆ™æ•°é‡ï¼š{len(rules)}")


def main():
    print("===== AdGuard Home è§„åˆ™æ•´åˆå·¥å…·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =====")
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½ {len(UPSTREAM_RULES)} ä¸ªä¸Šæ¸¸è§„åˆ™...")
    
    all_rules = []
    for url in UPSTREAM_RULES:
        rules = download_rule(url)
        all_rules.extend(rules)
    
    print(f"\nğŸ“¦ æ€»ä¸‹è½½è§„åˆ™æ•°ï¼š{len(all_rules)}")
    print("ğŸ”§ æ­£åœ¨æ•´åˆè§„åˆ™ï¼ˆDNSéªŒè¯ + æ³›åŒ–åˆå¹¶ + ä¼˜å…ˆçº§å¤„ç† + å†²çªè§£å†³ï¼‰...")
    
    merged_rules = merge_rules(all_rules)
    generate_final_file(merged_rules)

if __name__ == "__main__":
    main()
